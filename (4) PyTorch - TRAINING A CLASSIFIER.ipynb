{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an image classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and normalize CIFAR10\n",
    "\n",
    "> #### CIFAR10 dataset\n",
    "> Link: [CIFAR-10 - Object Recognition in Images](https://www.kaggle.com/competitions/cifar-10/overview)\n",
    ">\n",
    "> `CIFAR-10  is an established computer-vision dataset used for object recognition. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6000 images per class.`\n",
    "> 1. Classes:\n",
    ">    1. `airplane`\n",
    ">    2. `automobile`\n",
    ">    3. `bird`\n",
    ">    4. `cat`\n",
    ">    5. `deer`\n",
    ">    6. `dog`\n",
    ">    7. `frog`\n",
    ">    8. `horse`\n",
    ">    9. `ship`\n",
    ">    10. `truck`\n",
    "> 2. The images in `CIFAR-10` are of size **3x32x32**, *i.e. 3-channel (<span style=\"color:red\">red</span>, <span style=\"color:green\">green</span>, <span style=\"color:blue\">blue</span>) color images of 32x32 pixels in size.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the neural network terminology:\n",
    "* one epoch = one forward pass and one backward pass of all the training examples.\n",
    "* batch_size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n",
    "* number of iterations = number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes).\n",
    "\n",
    "Example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "`ToTensor() — Convert anImage datasets to Tensors`\n",
    "\n",
    "`Normalize() — Normalize the pixel values to that of the dataset that you are using`\n",
    "\n",
    "we will use the CIFAR10 dataset. It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "381ad78600b0f6139d0ae7ac9cdbbcb8374a07bc1f0a0957528f0a73243bf45e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
